{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe63d80",
   "metadata": {},
   "source": [
    "# Graph & Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028321a",
   "metadata": {},
   "source": [
    "This notebook contains the code for building our network graph and routing algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33cbdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import LineString, MultiLineString, Point\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import folium\n",
    "\n",
    "# set project root\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# module imports\n",
    "from src.routing_graph import (\n",
    "    GraphBuildConfig,\n",
    "    RiskConfig,\n",
    "    RoutingGraphArtifacts,\n",
    "    build_routing_graph,\n",
    "    build_graph_with_risk,\n",
    "    verify_graph_sanity,\n",
    "    NodeKey,\n",
    ")\n",
    "from src.routing_algorithm import (\n",
    "    nearest_graph_node,\n",
    "    route_stats,\n",
    "    shortest_path_by,\n",
    "    constrained_min_risk_route,\n",
    "    run_one_od_routing,\n",
    "    path_to_multiline_latlon,\n",
    ")\n",
    "\n",
    "DATA_DIR = Path(\"..\") / \"data\" / \"panel\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162500e",
   "metadata": {},
   "source": [
    "The next cell loads the data frames that were constructed through the merging procedure executed in `01_data_preparation.ipynb` and derives longitude and latitude data from the the geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcc22668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>geometry</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>light_condition</th>\n",
       "      <th>accident_type</th>\n",
       "      <th>accident_kind</th>\n",
       "      <th>injury_severity</th>\n",
       "      <th>index_node</th>\n",
       "      <th>node_id</th>\n",
       "      <th>dist_node</th>\n",
       "      <th>has_crossing</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20226</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (13.48861 52.46449)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.488608</td>\n",
       "      <td>52.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3881</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>POINT (13.60631 52.45275)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>night (22h-7h)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.606309</td>\n",
       "      <td>52.452751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1750</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (13.3133 52.57682)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.313300</td>\n",
       "      <td>52.576824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (13.68352 52.37053)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>evening (18h-22h)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.683520</td>\n",
       "      <td>52.370531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13090</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>POINT (13.45826 52.48577)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>evening (18h-22h)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>9.360363</td>\n",
       "      <td>True</td>\n",
       "      <td>13.458259</td>\n",
       "      <td>52.485774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15391</th>\n",
       "      <td>3319</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>POINT (13.21397 52.53838)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.213969</td>\n",
       "      <td>52.538384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15392</th>\n",
       "      <td>6510</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (13.32488 52.50253)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>night (22h-7h)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.324880</td>\n",
       "      <td>52.502526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15393</th>\n",
       "      <td>22519</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>POINT (13.45723 52.56107)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>evening (18h-22h)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.457235</td>\n",
       "      <td>52.561067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15394</th>\n",
       "      <td>19908</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (13.55801 52.45571)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>15.145493</td>\n",
       "      <td>True</td>\n",
       "      <td>13.558009</td>\n",
       "      <td>52.455714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>21785</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>POINT (13.55801 52.45571)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>15.145493</td>\n",
       "      <td>True</td>\n",
       "      <td>13.558009</td>\n",
       "      <td>52.455714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15396 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc_id  year  month                   geometry weekday_type  \\\n",
       "0       20226  2021      4  POINT (13.48861 52.46449)      weekday   \n",
       "1        3881  2019      9  POINT (13.60631 52.45275)      weekday   \n",
       "2        1750  2019      5   POINT (13.3133 52.57682)      weekday   \n",
       "3        1922  2019      5  POINT (13.68352 52.37053)      weekday   \n",
       "4       13090  2022      8  POINT (13.45826 52.48577)      weekday   \n",
       "...       ...   ...    ...                        ...          ...   \n",
       "15391    3319  2019      8  POINT (13.21397 52.53838)      weekday   \n",
       "15392    6510  2020      4  POINT (13.32488 52.50253)      weekday   \n",
       "15393   22519  2021      9  POINT (13.45723 52.56107)      weekday   \n",
       "15394   19908  2021      3  POINT (13.55801 52.45571)      weekday   \n",
       "15395   21785  2021      7  POINT (13.55801 52.45571)      weekday   \n",
       "\n",
       "               time_of_day  light_condition  accident_type  accident_kind  \\\n",
       "0      work_hours (7h-18h)                0              5              1   \n",
       "1           night (22h-7h)                1              2              5   \n",
       "2      work_hours (7h-18h)                0              2              5   \n",
       "3        evening (18h-22h)                0              1              0   \n",
       "4        evening (18h-22h)                0              1              0   \n",
       "...                    ...              ...            ...            ...   \n",
       "15391  work_hours (7h-18h)                0              2              5   \n",
       "15392       night (22h-7h)                2              1              0   \n",
       "15393    evening (18h-22h)                0              2              5   \n",
       "15394  work_hours (7h-18h)                0              2              5   \n",
       "15395  work_hours (7h-18h)                0              2              5   \n",
       "\n",
       "       injury_severity  index_node  node_id  dist_node  has_crossing  \\\n",
       "0                    2         NaN      NaN        NaN         False   \n",
       "1                    3         NaN      NaN        NaN         False   \n",
       "2                    3         NaN      NaN        NaN         False   \n",
       "3                    1         NaN      NaN        NaN         False   \n",
       "4                    3      1482.0   1518.0   9.360363          True   \n",
       "...                ...         ...      ...        ...           ...   \n",
       "15391                3         NaN      NaN        NaN         False   \n",
       "15392                3         NaN      NaN        NaN         False   \n",
       "15393                3         NaN      NaN        NaN         False   \n",
       "15394                3      1790.0   1852.0  15.145493          True   \n",
       "15395                3      1790.0   1852.0  15.145493          True   \n",
       "\n",
       "       longitude   latitude  \n",
       "0      13.488608  52.464495  \n",
       "1      13.606309  52.452751  \n",
       "2      13.313300  52.576824  \n",
       "3      13.683520  52.370531  \n",
       "4      13.458259  52.485774  \n",
       "...          ...        ...  \n",
       "15391  13.213969  52.538384  \n",
       "15392  13.324880  52.502526  \n",
       "15393  13.457235  52.561067  \n",
       "15394  13.558009  52.455714  \n",
       "15395  13.558009  52.455714  \n",
       "\n",
       "[15396 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_node_df = gpd.read_parquet(DATA_DIR / \"acc_node.parquet\")\n",
    "segments_df = gpd.read_parquet(DATA_DIR / \"segments_with_risk.parquet\")\n",
    "junction_df = gpd.read_parquet(DATA_DIR / \"junctions_with_risk.parquet\")\n",
    "\n",
    "# Ensure expected CRS for folium (lat/lon)\n",
    "junction_df = junction_df.to_crs(epsg=4326)\n",
    "acc_node_df = acc_node_df.to_crs(epsg=4326)\n",
    "segments_df = segments_df.to_crs(epsg=4326)\n",
    "\n",
    "# Create longitude and latitude columns from geometry\n",
    "if \"longitude\" not in junction_df.columns:\n",
    "    junction_df[\"longitude\"] = junction_df.geometry.x\n",
    "if \"latitude\" not in junction_df.columns:\n",
    "    junction_df[\"latitude\"] = junction_df.geometry.y\n",
    "\n",
    "if \"longitude\" not in acc_node_df.columns:\n",
    "    acc_node_df[\"longitude\"] = acc_node_df.geometry.x\n",
    "if \"latitude\" not in acc_node_df.columns:\n",
    "    acc_node_df[\"latitude\"] = acc_node_df.geometry.y\n",
    "\n",
    "\n",
    "acc_node_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c6b57",
   "metadata": {},
   "source": [
    "## Prepare spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026172e",
   "metadata": {},
   "source": [
    "The following cell constructs a crossings GeoDataFrame with one geometry per `node_id`, derives longitude and latitude coordinates from segment geometries, and creates a coordinate-to-segment mapping for efficient spatial lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d7398e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one geometry per node_id\n",
    "crossings_gdf = (\n",
    "    junction_df[[\"node_id\", \"geometry\"]]\n",
    "    .dropna(subset=[\"node_id\", \"geometry\"])\n",
    "    .drop_duplicates(subset=[\"node_id\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "crossings_gdf = gpd.GeoDataFrame(\n",
    "    crossings_gdf,\n",
    "    geometry=\"geometry\",\n",
    "    crs=junction_df.crs,\n",
    ")\n",
    "\n",
    "rep = segments_df.geometry.representative_point()\n",
    "segments_df[\"longitude\"] = rep.x\n",
    "segments_df[\"latitude\"] = rep.y\n",
    "\n",
    "coords_to_segments = defaultdict(set)\n",
    "\n",
    "for name, geom in zip(segments_df[\"counter_name\"], segments_df.geometry):\n",
    "    for lon, lat in geom.coords:\n",
    "        coords_to_segments[(lat, lon)].add(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde4ad0",
   "metadata": {},
   "source": [
    "## Run routing for one OD pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a543dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example origin-destination routing for Berlin\n",
    "metric_epsg = 32633\n",
    "ETA = 1.0\n",
    "EPS = 0.10\n",
    "\n",
    "# These are Berlin coordinates (lon, lat)\n",
    "origin_lonlat = (13.3777, 52.5163)    # Brandenburg Gate area\n",
    "dest_lonlat = (13.4541, 52.5110)      # East Berlin\n",
    "\n",
    "result_berlin = run_one_od_routing(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    origin_lonlat=origin_lonlat,\n",
    "    dest_lonlat=dest_lonlat,\n",
    "    eps=EPS,\n",
    "    eta=ETA,\n",
    ")\n",
    "\n",
    "if result_berlin.get(\"status\") == \"disconnected\":\n",
    "    raise RuntimeError(\"OD pair disconnected in the routing graph.\")\n",
    "\n",
    "G = result_berlin.get(\"graph\", None)\n",
    "if G is None:\n",
    "    # fallback \n",
    "    artifacts = build_graph_with_risk(\n",
    "        segments_gdf=segments_df,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_gdf=junction_df,\n",
    "        risk_cfg=RiskConfig(eta=ETA),\n",
    "    )\n",
    "\n",
    "    G = artifacts.G\n",
    "\n",
    "# Shortest path geometry: choose_by length\n",
    "shortest_geom = path_to_multiline_latlon(\n",
    "    G, result_berlin[\"shortest_length_path\"], metric_epsg=metric_epsg, choose_by=\"length_m\"\n",
    ")\n",
    "\n",
    "# Safe path geometry: choose_by risk_total\n",
    "safe_geom = path_to_multiline_latlon(\n",
    "    G, result_berlin[\"constrained_min_risk_path\"], metric_epsg=metric_epsg, choose_by=\"risk_total\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5effb40",
   "metadata": {},
   "source": [
    "## Run routing over many OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "807a5030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_nodes': 3048, 'n_edges': 4335, 'seg_risk_min': 2.1921227354338257e-07, 'seg_risk_median': 5.265051380918785e-05, 'seg_risk_max': 0.004930354303062096, 'risk_total_median': 0.00011021206386569035, 'risk_total_max': 0.004983293192078483, 'length_median': 372.42039723715783, 'node_penalty_nonzero_share': 0.9983852364475202, 'graph_node_ids_attached': 2862, 'notes': 'Attached node_id to 2862/3048 graph nodes (snap<= 20.0m). Risk objective uses eta=1.0 for junction penalty weighting.'}\n",
      "          delta_L     delta_R\n",
      "count  300.000000  300.000000\n",
      "mean     0.032753    0.304537\n",
      "std      0.028940    0.213010\n",
      "min      0.000000    0.000000\n",
      "25%      0.006007    0.126384\n",
      "50%      0.027830    0.315455\n",
      "75%      0.053915    0.469907\n",
      "max      0.099532    0.823890\n"
     ]
    }
   ],
   "source": [
    "# Extensive evaluation loop over MANY OD pairs\n",
    "\n",
    "def _sample_reachable_od_pairs(\n",
    "    G: nx.Graph,\n",
    "    n_pairs: int,\n",
    "    *,\n",
    "    seed: int = 7,\n",
    "    min_euclid_m: float = 1500.0,\n",
    "    max_tries: int = 200000,\n",
    ") -> list[tuple[NodeKey, NodeKey]]:\n",
    "    \"\"\"\n",
    "    Samples OD pairs as graph nodes ensuring:\n",
    "      - O != D\n",
    "      - straight-line distance >= min_euclid_m\n",
    "      - O and D are connected (same component) in the undirected sense\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    nodes = list(G.nodes())\n",
    "    if len(nodes) < 2:\n",
    "        return []\n",
    "\n",
    "    comp_map = {}\n",
    "    for cid, comp in enumerate(nx.connected_components(G.to_undirected())):\n",
    "        for n in comp:\n",
    "            comp_map[n] = cid\n",
    "\n",
    "    pairs: list[tuple[NodeKey, NodeKey]] = []\n",
    "    tries = 0\n",
    "    while len(pairs) < n_pairs and tries < max_tries:\n",
    "        tries += 1\n",
    "        a = rng.choice(nodes)\n",
    "        b = rng.choice(nodes)\n",
    "        if a == b:\n",
    "            continue\n",
    "        if comp_map.get(a) != comp_map.get(b):\n",
    "            continue\n",
    "\n",
    "        dx = float(a[0] - b[0])\n",
    "        dy = float(a[1] - b[1])\n",
    "        if math.sqrt(dx * dx + dy * dy) < min_euclid_m:\n",
    "            continue\n",
    "\n",
    "        pairs.append((a, b))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def evaluate_many_od_pairs(\n",
    "    *,\n",
    "    segments_panel_gdf: gpd.GeoDataFrame,\n",
    "    crossings_gdf: gpd.GeoDataFrame,\n",
    "    junction_panel_gdf: gpd.GeoDataFrame,\n",
    "    n_pairs: int = 200,\n",
    "    eps: float = 0.10,\n",
    "    eta: float = 1.0, # junction importance\n",
    "    metric_epsg: int = 32633,\n",
    "    seed: int = 7,\n",
    "    min_euclid_m: float = 1500.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Builds month graph once, samples many reachable OD pairs on the graph,\n",
    "    and evaluates:\n",
    "      - shortest-by-length (P_dist)\n",
    "      - optional shortest-by-cost (mixed objective)\n",
    "      - constrained min-risk (P_safe) minimizing risk_total under length constraint\n",
    "\n",
    "    Returns a DataFrame with per-OD statistics + metadata.\n",
    "    \"\"\"\n",
    "    artifacts = build_graph_with_risk(\n",
    "        segments_panel_gdf,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_panel_gdf=junction_panel_gdf,\n",
    "        graph_cfg=GraphBuildConfig(metric_epsg=metric_epsg),\n",
    "        risk_cfg=RiskConfig(eta=eta),\n",
    "        node_snap_m=20.0,\n",
    "    )\n",
    "\n",
    "    sanity = verify_graph_sanity(\n",
    "        artifacts,\n",
    "        expect_junction_penalties=(eta != 0.0),\n",
    "    )\n",
    "    G = artifacts.G\n",
    "\n",
    "    od_pairs = _sample_reachable_od_pairs(G, n_pairs, seed=seed, min_euclid_m=min_euclid_m)\n",
    "    if len(od_pairs) == 0:\n",
    "        raise ValueError(\"Could not sample any reachable OD pairs. Check graph connectivity / size.\")\n",
    "\n",
    "    rows = []\n",
    "    n_skipped = 0\n",
    "\n",
    "    for i, (src, dst) in enumerate(od_pairs):\n",
    "        # 1) Shortest length (P_dist)\n",
    "        p_len = shortest_path_by(G, src, dst, weight=\"length_m\")\n",
    "        if p_len is None:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        st_len = route_stats(G, p_len, choose_by=\"length_m\")\n",
    "        shortest_len = float(st_len[\"length_m\"])\n",
    "        max_len = (1.0 + eps) * shortest_len\n",
    "\n",
    "        \n",
    "        # 2) Constrained min-risk minimizing risk_total\n",
    "        p_safe = constrained_min_risk_route(\n",
    "            G,\n",
    "            src,\n",
    "            dst,\n",
    "            eps=eps,\n",
    "            length_attr=\"length_m\",\n",
    "            risk_attr=\"risk_total\",\n",
    "        )\n",
    "        if p_safe is None:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        st_safe = route_stats(G, p_safe, choose_by=\"risk_total\")\n",
    "\n",
    "        # Route-level risk in Methods is R(P) = sum risk_total\n",
    "        R_len = float(st_len[\"risk_total_sum\"])\n",
    "        R_safe = float(st_safe[\"risk_total_sum\"])\n",
    "\n",
    "        row = {\n",
    "            \"pair_idx\": i,\n",
    "            \"src_x\": float(src[0]),\n",
    "            \"src_y\": float(src[1]),\n",
    "            \"dst_x\": float(dst[0]),\n",
    "            \"dst_y\": float(dst[1]),\n",
    "\n",
    "            \"shortest_len_m\": shortest_len,\n",
    "            \"shortest_risk_total_sum\": R_len,\n",
    "\n",
    "            \"safe_len_m\": float(st_safe[\"length_m\"]),\n",
    "            \"safe_risk_total_sum\": R_safe,\n",
    "\n",
    "            \"len_constraint_max_m\": float(max_len),\n",
    "            \"safe_feasible\": bool(float(st_safe[\"length_m\"]) <= max_len + 1e-6),\n",
    "        }\n",
    "\n",
    "        \n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Trade-offs relative to shortest-distance route\n",
    "    df[\"delta_L\"] = (df[\"safe_len_m\"] - df[\"shortest_len_m\"]) / df[\"shortest_len_m\"]\n",
    "    df[\"delta_R\"] = (df[\"shortest_risk_total_sum\"] - df[\"safe_risk_total_sum\"]) / df[\"shortest_risk_total_sum\"].replace(0, np.nan)\n",
    "\n",
    "    \n",
    "    # Metadata for reproducibility\n",
    "    df.attrs[\"graph_sanity\"] = sanity\n",
    "    df.attrs[\"notes\"] = artifacts.notes\n",
    "    df.attrs[\"eps\"] = eps\n",
    "    df.attrs[\"eta\"] = eta\n",
    "    df.attrs[\"seed\"] = seed\n",
    "    df.attrs[\"min_euclid_m\"] = min_euclid_m\n",
    "    df.attrs[\"n_pairs_requested\"] = n_pairs\n",
    "    df.attrs[\"n_pairs_sampled\"] = len(od_pairs)\n",
    "    df.attrs[\"n_pairs_used\"] = len(df)\n",
    "    df.attrs[\"n_pairs_skipped\"] = n_skipped\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "eval_df = evaluate_many_od_pairs(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    n_pairs=300,\n",
    "    eps=0.10,\n",
    "    eta=1.0,             \n",
    "    seed=7,\n",
    "    min_euclid_m=2000.0,\n",
    ")\n",
    "print(eval_df.attrs[\"graph_sanity\"])\n",
    "print(eval_df[[\"delta_L\", \"delta_R\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff1429",
   "metadata": {},
   "source": [
    "## Loop routing over all months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9aadc",
   "metadata": {},
   "source": [
    "Following [Natera Orozco et al. (2020)](https://doi.org/10.1098/rsos.201130), we evaluate our routing algorithm using `N_PAIRS = 1000` randomly selected origin-destination pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5e849d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "ETA_LIST = [0.0, 0.5, 1.0]\n",
    "EPS_LIST = [0.05, 0.10, 0.20]\n",
    "N_PAIRS = 1000\n",
    "\n",
    "for ETA in ETA_LIST:\n",
    "    for EPS in EPS_LIST:\n",
    "        try:\n",
    "            eval_df = evaluate_many_od_pairs(\n",
    "                segments_panel_gdf=segments_df,\n",
    "                crossings_gdf=crossings_gdf,\n",
    "                junction_panel_gdf=junction_df,\n",
    "                n_pairs=N_PAIRS,\n",
    "                eps=EPS,\n",
    "                eta=ETA,\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"[skip] eta={ETA}, eps={EPS}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if eval_df is None or len(eval_df) == 0:\n",
    "            print(f\"[skip] eta={ETA}, eps={EPS}: empty evaluation frame\")\n",
    "            continue\n",
    "\n",
    "        eval_df = eval_df.copy()\n",
    "        eval_df[\"eta\"] = ETA\n",
    "        eval_df[\"eps\"] = EPS\n",
    "        eval_df[\"n_pairs_target\"] = N_PAIRS\n",
    "        results.append(eval_df)\n",
    "\n",
    "if not results:\n",
    "    raise RuntimeError(\"No valid OD-pair evaluations.\")\n",
    "\n",
    "all_eval = pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77f61de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eval.attrs if hasattr(all_eval, \"attrs\") else \"attrs lost on concat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4caee13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair_idx', 'src_x', 'src_y', 'dst_x', 'dst_y', 'shortest_len_m',\n",
       "       'shortest_risk_total_sum', 'safe_len_m', 'safe_risk_total_sum',\n",
       "       'len_constraint_max_m', 'safe_feasible', 'delta_L', 'delta_R', 'eta',\n",
       "       'eps', 'n_pairs_target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1f45955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/992p8knd6g5flm6m0p856jlw0000gn/T/ipykernel_16423/3311492509.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>eps</th>\n",
       "      <th>n_pairs</th>\n",
       "      <th>feasible_share</th>\n",
       "      <th>median_delta_L</th>\n",
       "      <th>iqr_delta_L</th>\n",
       "      <th>median_delta_R</th>\n",
       "      <th>iqr_delta_R</th>\n",
       "      <th>share_delta_R_pos</th>\n",
       "      <th>median_shortest_len_m</th>\n",
       "      <th>median_safe_len_m</th>\n",
       "      <th>median_shortest_risk</th>\n",
       "      <th>median_safe_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.451</td>\n",
       "      <td>76.1</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15092.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.401</td>\n",
       "      <td>75.3</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15097.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.363</td>\n",
       "      <td>75.9</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15092.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.388</td>\n",
       "      <td>86.0</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15461.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.370</td>\n",
       "      <td>86.4</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15491.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.345</td>\n",
       "      <td>86.3</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.353</td>\n",
       "      <td>90.6</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15841.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.323</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15879.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.318</td>\n",
       "      <td>91.8</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>15879.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eta   eps  n_pairs  feasible_share  median_delta_L  iqr_delta_L  \\\n",
       "0  0.0  0.05   1000.0           100.0           0.009        0.026   \n",
       "1  0.5  0.05   1000.0           100.0           0.008        0.026   \n",
       "2  1.0  0.05   1000.0           100.0           0.008        0.026   \n",
       "3  0.0  0.10   1000.0           100.0           0.025        0.042   \n",
       "4  0.5  0.10   1000.0           100.0           0.026        0.046   \n",
       "5  1.0  0.10   1000.0           100.0           0.028        0.047   \n",
       "6  0.0  0.20   1000.0           100.0           0.038        0.072   \n",
       "7  0.5  0.20   1000.0           100.0           0.047        0.089   \n",
       "8  1.0  0.20   1000.0           100.0           0.050        0.086   \n",
       "\n",
       "   median_delta_R  iqr_delta_R  share_delta_R_pos  median_shortest_len_m  \\\n",
       "0           0.246        0.451               76.1                14881.5   \n",
       "1           0.208        0.401               75.3                14881.5   \n",
       "2           0.185        0.363               75.9                14881.5   \n",
       "3           0.377        0.388               86.0                14881.5   \n",
       "4           0.331        0.370               86.4                14881.5   \n",
       "5           0.305        0.345               86.3                14881.5   \n",
       "6           0.425        0.353               90.6                14881.5   \n",
       "7           0.404        0.323               92.0                14881.5   \n",
       "8           0.378        0.318               91.8                14881.5   \n",
       "\n",
       "   median_safe_len_m  median_shortest_risk  median_safe_risk  \n",
       "0            15092.7                   0.0               0.0  \n",
       "1            15097.7                   0.0               0.0  \n",
       "2            15092.7                   0.0               0.0  \n",
       "3            15461.1                   0.0               0.0  \n",
       "4            15491.8                   0.0               0.0  \n",
       "5            15470.0                   0.0               0.0  \n",
       "6            15841.2                   0.0               0.0  \n",
       "7            15879.0                   0.0               0.0  \n",
       "8            15879.0                   0.0               0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q(x, p):\n",
    "    return float(np.nanquantile(x, p))\n",
    "\n",
    "summary = (\n",
    "    all_eval\n",
    "    .groupby([\"eta\", \"eps\"], as_index=False)\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"n_pairs\": int(len(g)),\n",
    "        \"feasible_share\": float(np.mean(g[\"safe_feasible\"].astype(bool))),\n",
    "\n",
    "        \"median_delta_L\": float(np.nanmedian(g[\"delta_L\"])),\n",
    "        \"iqr_delta_L\": float(q(g[\"delta_L\"], 0.75) - q(g[\"delta_L\"], 0.25)),\n",
    "\n",
    "        \"median_delta_R\": float(np.nanmedian(g[\"delta_R\"])),\n",
    "        \"iqr_delta_R\": float(q(g[\"delta_R\"], 0.75) - q(g[\"delta_R\"], 0.25)),\n",
    "\n",
    "        \"share_delta_R_pos\": float(np.mean(g[\"delta_R\"] > 0)),\n",
    "\n",
    "        \"median_shortest_len_m\": float(np.nanmedian(g[\"shortest_len_m\"])),\n",
    "        \"median_safe_len_m\": float(np.nanmedian(g[\"safe_len_m\"])),\n",
    "\n",
    "        \"median_shortest_risk\": float(np.nanmedian(g[\"shortest_risk_total_sum\"])),\n",
    "        \"median_safe_risk\": float(np.nanmedian(g[\"safe_risk_total_sum\"])),\n",
    "    }))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "summary_fmt = summary.copy()\n",
    "summary_fmt[\"feasible_share\"] = (100 * summary_fmt[\"feasible_share\"]).round(1)\n",
    "summary_fmt[\"share_delta_R_pos\"] = (100 * summary_fmt[\"share_delta_R_pos\"]).round(1)\n",
    "\n",
    "for c in [\"median_delta_L\", \"iqr_delta_L\", \"median_delta_R\", \"iqr_delta_R\"]:\n",
    "    summary_fmt[c] = summary_fmt[c].round(3)\n",
    "\n",
    "for c in [\"median_shortest_len_m\", \"median_safe_len_m\", \"median_shortest_risk\", \"median_safe_risk\"]:\n",
    "    summary_fmt[c] = summary_fmt[c].round(1)\n",
    "\n",
    "summary_fmt = summary_fmt.sort_values([\"eps\", \"eta\"]).reset_index(drop=True)\n",
    "\n",
    "summary_fmt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
