{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe63d80",
   "metadata": {},
   "source": [
    "# Graph Build + Routing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028321a",
   "metadata": {},
   "source": [
    "### Import neccessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33cbdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import LineString, Point\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import folium\n",
    "\n",
    "# set project root\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Save map to figs folder\n",
    "fig_dir = PROJECT_ROOT / \"figs\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162500e",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcc22668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>geometry</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>light_condition</th>\n",
       "      <th>accident_type</th>\n",
       "      <th>accident_kind</th>\n",
       "      <th>injury_severity</th>\n",
       "      <th>index_node</th>\n",
       "      <th>node_id</th>\n",
       "      <th>dist_node</th>\n",
       "      <th>has_crossing</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29872</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (13.48861 52.46449)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.488608</td>\n",
       "      <td>52.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25448</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (13.19382 52.5337)</td>\n",
       "      <td>weekend</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.193820</td>\n",
       "      <td>52.533695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9074</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>POINT (13.60631 52.45275)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>night (22h-7h)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.606309</td>\n",
       "      <td>52.452751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6943</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (13.3133 52.57682)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.313300</td>\n",
       "      <td>52.576824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7115</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (13.68352 52.37053)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>evening (18h-22h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.683520</td>\n",
       "      <td>52.370531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21661</th>\n",
       "      <td>2500</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>POINT (13.34109 52.4852)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.341093</td>\n",
       "      <td>52.485197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21662</th>\n",
       "      <td>1817</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (13.44447 52.53412)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.444473</td>\n",
       "      <td>52.534120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21663</th>\n",
       "      <td>32165</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>POINT (13.45723 52.56107)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>evening (18h-22h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13.457235</td>\n",
       "      <td>52.561067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21664</th>\n",
       "      <td>29554</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (13.55801 52.45571)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>15.145493</td>\n",
       "      <td>True</td>\n",
       "      <td>13.558009</td>\n",
       "      <td>52.455714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21665</th>\n",
       "      <td>31431</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>POINT (13.55801 52.45571)</td>\n",
       "      <td>weekday</td>\n",
       "      <td>work_hours (7h-18h)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>15.145493</td>\n",
       "      <td>True</td>\n",
       "      <td>13.558009</td>\n",
       "      <td>52.455714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21666 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc_id  year  month                   geometry weekday_type  \\\n",
       "0       29872  2021      4  POINT (13.48861 52.46449)      weekday   \n",
       "1       25448  2024      3   POINT (13.19382 52.5337)      weekend   \n",
       "2        9074  2019      9  POINT (13.60631 52.45275)      weekday   \n",
       "3        6943  2019      5   POINT (13.3133 52.57682)      weekday   \n",
       "4        7115  2019      5  POINT (13.68352 52.37053)      weekday   \n",
       "...       ...   ...    ...                        ...          ...   \n",
       "21661    2500  2018      6   POINT (13.34109 52.4852)      weekday   \n",
       "21662    1817  2018      5  POINT (13.44447 52.53412)      weekday   \n",
       "21663   32165  2021      9  POINT (13.45723 52.56107)      weekday   \n",
       "21664   29554  2021      3  POINT (13.55801 52.45571)      weekday   \n",
       "21665   31431  2021      7  POINT (13.55801 52.45571)      weekday   \n",
       "\n",
       "               time_of_day  light_condition  accident_type  accident_kind  \\\n",
       "0      work_hours (7h-18h)              0.0              5              1   \n",
       "1      work_hours (7h-18h)              0.0              3              5   \n",
       "2           night (22h-7h)              1.0              2              5   \n",
       "3      work_hours (7h-18h)              0.0              2              5   \n",
       "4        evening (18h-22h)              0.0              1              0   \n",
       "...                    ...              ...            ...            ...   \n",
       "21661  work_hours (7h-18h)              0.0              5              1   \n",
       "21662  work_hours (7h-18h)              0.0              7              6   \n",
       "21663    evening (18h-22h)              0.0              2              5   \n",
       "21664  work_hours (7h-18h)              0.0              2              5   \n",
       "21665  work_hours (7h-18h)              0.0              2              5   \n",
       "\n",
       "       injury_severity  index_node  node_id  dist_node  has_crossing  \\\n",
       "0                    2         NaN      NaN        NaN         False   \n",
       "1                    3         NaN      NaN        NaN         False   \n",
       "2                    3         NaN      NaN        NaN         False   \n",
       "3                    3         NaN      NaN        NaN         False   \n",
       "4                    1         NaN      NaN        NaN         False   \n",
       "...                ...         ...      ...        ...           ...   \n",
       "21661                3         NaN      NaN        NaN         False   \n",
       "21662                3         NaN      NaN        NaN         False   \n",
       "21663                3         NaN      NaN        NaN         False   \n",
       "21664                3      1790.0   1852.0  15.145493          True   \n",
       "21665                3      1790.0   1852.0  15.145493          True   \n",
       "\n",
       "       longitude   latitude  \n",
       "0      13.488608  52.464495  \n",
       "1      13.193820  52.533695  \n",
       "2      13.606309  52.452751  \n",
       "3      13.313300  52.576824  \n",
       "4      13.683520  52.370531  \n",
       "...          ...        ...  \n",
       "21661  13.341093  52.485197  \n",
       "21662  13.444473  52.534120  \n",
       "21663  13.457235  52.561067  \n",
       "21664  13.558009  52.455714  \n",
       "21665  13.558009  52.455714  \n",
       "\n",
       "[21666 rows x 16 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junction_df = gpd.read_parquet(\"../data/merged/berlin_bike_accident_node_panel.parquet\")\n",
    "acc_node_df = gpd.read_parquet(\"../data/merged/acc_node.parquet\")\n",
    "\n",
    "# Ensure expected CRS for folium (lat/lon)\n",
    "junction_df = junction_df.to_crs(epsg=4326)\n",
    "acc_node_df = acc_node_df.to_crs(epsg=4326)\n",
    "\n",
    "# If these columns aren't present yet, create them from geometry\n",
    "if \"longitude\" not in junction_df.columns:\n",
    "    junction_df[\"longitude\"] = junction_df.geometry.x\n",
    "if \"latitude\" not in junction_df.columns:\n",
    "    junction_df[\"latitude\"] = junction_df.geometry.y\n",
    "\n",
    "if \"longitude\" not in acc_node_df.columns:\n",
    "    acc_node_df[\"longitude\"] = acc_node_df.geometry.x\n",
    "if \"latitude\" not in acc_node_df.columns:\n",
    "    acc_node_df[\"latitude\"] = acc_node_df.geometry.y\n",
    "\n",
    "# Backwards compatibility: if you didn't add has_crossing, derive it\n",
    "if \"has_crossing\" not in acc_node_df.columns:\n",
    "    acc_node_df[\"has_crossing\"] = acc_node_df[\"node_id\"].notna()\n",
    "\n",
    "acc_node_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78770082",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df = gpd.read_parquet(\"../data/merged/berlin_bike_accident_strava_risk_core_panel.parquet\").to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c6b57",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d7398e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossings_gdf: (2924, 2)\n"
     ]
    }
   ],
   "source": [
    "# one geometry per node_id\n",
    "crossings_gdf = (\n",
    "    junction_df[[\"node_id\", \"geometry\"]]\n",
    "    .dropna(subset=[\"node_id\", \"geometry\"])\n",
    "    .drop_duplicates(subset=[\"node_id\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "crossings_gdf = gpd.GeoDataFrame(\n",
    "    crossings_gdf,\n",
    "    geometry=\"geometry\",\n",
    "    crs=junction_df.crs,\n",
    ")\n",
    "\n",
    "print(\"crossings_gdf:\", crossings_gdf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee595225",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = segments_df.geometry.representative_point()\n",
    "segments_df[\"longitude\"] = rep.x\n",
    "segments_df[\"latitude\"] = rep.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1935bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_to_segments = defaultdict(set)\n",
    "\n",
    "for name, geom in zip(segments_df[\"counter_name\"], segments_df.geometry):\n",
    "    for lon, lat in geom.coords:\n",
    "        coords_to_segments[(lat, lon)].add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99c859",
   "metadata": {},
   "source": [
    "# Graph + routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26964d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code builds a routing graph for a given (year, month), attaches risk,\n",
    "# and provides shortest / constrained-min-risk routing utilities.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import LineString, Point\n",
    "\n",
    "\n",
    "# Helpers\n",
    "\n",
    "NodeKey = Tuple[float, float]\n",
    "\n",
    "\n",
    "def _edge_endpoints_as_node_keys(linestring: LineString, ndigits: int = 0) -> Tuple[NodeKey, NodeKey]:\n",
    "    \"\"\"\n",
    "    Create stable node keys from LineString endpoints in a metric CRS.\n",
    "\n",
    "    For UTM meters:\n",
    "      ndigits=0 => 1m rounding (robust)\n",
    "      ndigits=1 => 0.1m rounding (less robust)\n",
    "      ndigits=3 => 1mm rounding (usually too strict)\n",
    "    \"\"\"\n",
    "    (x1, y1) = linestring.coords[0]\n",
    "    (x2, y2) = linestring.coords[-1]\n",
    "    a = (round(float(x1), ndigits), round(float(y1), ndigits))\n",
    "    b = (round(float(x2), ndigits), round(float(y2), ndigits))\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def _risk_fallback_value(series: pd.Series, *, strategy: str = \"median\", default: float = 0.0) -> float:\n",
    "    \"\"\"\n",
    "    Decide a safe fallback risk if a segment/node risk is NaN.\n",
    "\n",
    "    strategy:\n",
    "      - \"median\": median of observed values for that month panel\n",
    "      - \"mean\": mean of observed values\n",
    "      - \"zero\": always 0\n",
    "      - \"high\": conservative high value (90th percentile if possible)\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    s = s[np.isfinite(s)]\n",
    "    if len(s) == 0:\n",
    "        return float(default)\n",
    "\n",
    "    if strategy == \"median\":\n",
    "        return float(np.nanmedian(s))\n",
    "    if strategy == \"mean\":\n",
    "        return float(np.nanmean(s))\n",
    "    if strategy == \"high\":\n",
    "        return float(np.nanpercentile(s, 90))\n",
    "    if strategy == \"zero\":\n",
    "        return 0.0\n",
    "\n",
    "    return float(np.nanmedian(s))\n",
    "\n",
    "\n",
    "def _build_node_risk_lookup(\n",
    "    junction_panel_gdf: gpd.GeoDataFrame,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    *,\n",
    "    node_id_col: str = \"node_id\",\n",
    "    node_risk_col: str = \"risk_accidents_per_10k_trips\",\n",
    "    fallback: float = 0.0,\n",
    "    fallback_strategy: str = \"median\",\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Returns dict[node_id(str)] -> node_risk for the given (year, month).\n",
    "\n",
    "    Notes:\n",
    "      - If (year, month) missing entirely: returns {} (caller chooses behavior).\n",
    "      - If a node risk value is NaN: filled by fallback computed from the month panel.\n",
    "    \"\"\"\n",
    "    if junction_panel_gdf is None or len(junction_panel_gdf) == 0:\n",
    "        return {}\n",
    "\n",
    "    j = junction_panel_gdf[(junction_panel_gdf[\"year\"] == year) & (junction_panel_gdf[\"month\"] == month)].copy()\n",
    "    if j.empty:\n",
    "        return {}\n",
    "\n",
    "    if node_risk_col not in j.columns:\n",
    "        raise KeyError(f\"Missing node risk column '{node_risk_col}' in junction_panel_gdf\")\n",
    "\n",
    "    # Ensure one row per node_id-month; if multiple exist, take mean (shouldn't happen, but safe).\n",
    "    j = j.groupby(node_id_col, as_index=False)[node_risk_col].mean()\n",
    "\n",
    "    fb = _risk_fallback_value(j[node_risk_col], strategy=fallback_strategy, default=fallback)\n",
    "    j[node_risk_col] = pd.to_numeric(j[node_risk_col], errors=\"coerce\").fillna(fb)\n",
    "\n",
    "    return dict(zip(j[node_id_col].astype(str), j[node_risk_col].astype(float)))\n",
    "\n",
    "\n",
    "def _attach_node_ids_to_graph_nodes(\n",
    "    G: nx.Graph,\n",
    "    crossings_gdf: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    metric_epsg: int = 32633,\n",
    "    node_id_col: str = \"node_id\",\n",
    "    max_snap_m: float = 20.0,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Map your existing 'node_id' (junctions/crossings) onto graph nodes.\n",
    "\n",
    "    We snap each crossing point to the nearest graph node (within max_snap_m).\n",
    "    Stores: G.nodes[node_key][\"node_id\"] = <id>\n",
    "\n",
    "    Critical for applying junction risk penalties.\n",
    "    \"\"\"\n",
    "    if crossings_gdf is None or len(crossings_gdf) == 0:\n",
    "        return\n",
    "\n",
    "    crossings_m = crossings_gdf.to_crs(epsg=metric_epsg).copy()\n",
    "\n",
    "    graph_nodes = list(G.nodes())\n",
    "    if len(graph_nodes) == 0:\n",
    "        return\n",
    "\n",
    "    graph_xy = np.array(graph_nodes, dtype=float)\n",
    "\n",
    "    for _, row in crossings_m.iterrows():\n",
    "        if row.geometry is None or row.geometry.is_empty:\n",
    "            continue\n",
    "\n",
    "        nid = str(row[node_id_col])\n",
    "        x, y = float(row.geometry.x), float(row.geometry.y)\n",
    "\n",
    "        d2 = (graph_xy[:, 0] - x) ** 2 + (graph_xy[:, 1] - y) ** 2\n",
    "        j = int(d2.argmin())\n",
    "        dist = float(math.sqrt(d2[j]))\n",
    "        if dist <= max_snap_m:\n",
    "            node_key = graph_nodes[j]\n",
    "            G.nodes[node_key][\"node_id\"] = nid\n",
    "\n",
    "\n",
    "def _iter_edges(G: nx.Graph):\n",
    "    \"\"\"\n",
    "    Unified iterator over edges returning (u, v, key, data) where key is None for non-multigraphs.\n",
    "    \"\"\"\n",
    "    if isinstance(G, nx.MultiGraph):\n",
    "        for u, v, k, data in G.edges(keys=True, data=True):\n",
    "            yield u, v, k, data\n",
    "    else:\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            yield u, v, None, data\n",
    "\n",
    "\n",
    "def _get_edge_data_for_step(G: nx.Graph, a, b, *, choose_by: str = \"length_m\") -> dict:\n",
    "    \"\"\"\n",
    "    For MultiGraph: pick the parallel edge (between a,b) that minimizes choose_by\n",
    "    (fallback to length_m).\n",
    "    For Graph: return edge data.\n",
    "    \"\"\"\n",
    "    if isinstance(G, nx.MultiGraph):\n",
    "        edges = G.get_edge_data(a, b)\n",
    "        if edges is None:\n",
    "            raise KeyError(f\"No edge between {a} and {b}\")\n",
    "\n",
    "        best = None\n",
    "        best_val = None\n",
    "        for _, d in edges.items():\n",
    "            val = d.get(choose_by, d.get(\"length_m\", 0.0))\n",
    "            if best is None or val < best_val:\n",
    "                best = d\n",
    "                best_val = val\n",
    "        return best\n",
    "    else:\n",
    "        d = G.get_edge_data(a, b)\n",
    "        if d is None:\n",
    "            raise KeyError(f\"No edge between {a} and {b}\")\n",
    "        return d\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Graph construction\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GraphBuildConfig:\n",
    "    metric_epsg: int = 32633\n",
    "    endpoint_ndigits: int = 0\n",
    "    seg_id_col: str = \"counter_name\"\n",
    "    seg_exposure_col_candidates: Tuple[str, ...] = (\"monthly_strava_trips\", \"sum_strava_total_trip_count\")\n",
    "    seg_risk_col_candidates: Tuple[str, ...] = (\"risk_accidents_per_10k_trips\", \"risk_accidents_per_trip\")\n",
    "    auto_scale_trip_risk_to_per_10k: bool = True\n",
    "    risk_fallback_strategy: str = \"median\"   # median/mean/high/zero\n",
    "    risk_fallback_default: float = 0.0\n",
    "    drop_edges_with_zero_exposure: bool = True\n",
    "    keep_parallel_edges: bool = True\n",
    "\n",
    "\n",
    "def build_routing_graph_for_month(\n",
    "    segments_panel_gdf: gpd.GeoDataFrame,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    *,\n",
    "    config: GraphBuildConfig = GraphBuildConfig(),\n",
    ") -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Build a routing graph for one (year, month) from segment LineStrings.\n",
    "\n",
    "    Nodes: segment endpoints (rounded in metric CRS).\n",
    "    Edges carry:\n",
    "      - segment_id\n",
    "      - length_m\n",
    "      - seg_risk (scaled for routing; per-10k trips)\n",
    "      - geometry\n",
    "    \"\"\"\n",
    "    df = segments_panel_gdf[(segments_panel_gdf[\"year\"] == year) & (segments_panel_gdf[\"month\"] == month)].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No segment rows found for year={year}, month={month}\")\n",
    "\n",
    "    df_m = df.to_crs(epsg=config.metric_epsg).copy()\n",
    "\n",
    "    # Pick exposure column\n",
    "    exposure_col = None\n",
    "    for c in config.seg_exposure_col_candidates:\n",
    "        if c in df_m.columns:\n",
    "            exposure_col = c\n",
    "            break\n",
    "    if exposure_col is None:\n",
    "        raise KeyError(f\"Missing exposure column. Tried: {config.seg_exposure_col_candidates}\")\n",
    "\n",
    "    # Pick risk column\n",
    "    risk_col = None\n",
    "    for c in config.seg_risk_col_candidates:\n",
    "        if c in df_m.columns:\n",
    "            risk_col = c\n",
    "            break\n",
    "    if risk_col is None:\n",
    "        raise KeyError(f\"Missing risk column. Tried: {config.seg_risk_col_candidates}\")\n",
    "\n",
    "    # Ensure uniqueness at segment-month level\n",
    "    if df_m[[config.seg_id_col, \"year\", \"month\"]].duplicated().any():\n",
    "        dups = int(df_m[[config.seg_id_col, \"year\", \"month\"]].duplicated().sum())\n",
    "        raise ValueError(f\"segments_panel_gdf has {dups} duplicate rows for (segment,year,month). Fix upstream aggregation.\")\n",
    "\n",
    "    df_m[exposure_col] = pd.to_numeric(df_m[exposure_col], errors=\"coerce\")\n",
    "    if config.drop_edges_with_zero_exposure:\n",
    "        df_m = df_m[df_m[exposure_col].fillna(0) > 0].copy()\n",
    "\n",
    "    # Compute fallback risk (month-specific)\n",
    "    fb = _risk_fallback_value(df_m[risk_col], strategy=config.risk_fallback_strategy, default=config.risk_fallback_default)\n",
    "\n",
    "    # Build graph\n",
    "    G = nx.MultiGraph() if config.keep_parallel_edges else nx.Graph()\n",
    "\n",
    "    for _, row in df_m.iterrows():\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            continue\n",
    "        if not isinstance(geom, LineString):\n",
    "            # If MultiLineString, take the longest component\n",
    "            try:\n",
    "                parts = list(geom.geoms)\n",
    "                parts = [p for p in parts if isinstance(p, LineString) and not p.is_empty]\n",
    "                if not parts:\n",
    "                    continue\n",
    "                geom = max(parts, key=lambda g: g.length)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        u, v = _edge_endpoints_as_node_keys(geom, ndigits=config.endpoint_ndigits)\n",
    "        seg_id = str(row[config.seg_id_col])\n",
    "        length_m = float(geom.length)\n",
    "\n",
    "        seg_risk = pd.to_numeric(row[risk_col], errors=\"coerce\")\n",
    "        if pd.isna(seg_risk):\n",
    "            seg_risk = fb\n",
    "        seg_risk = float(seg_risk)\n",
    "\n",
    "        # If only per-trip risk exists, scale to per-10k for routing stability\n",
    "        if (risk_col == \"risk_accidents_per_trip\") and config.auto_scale_trip_risk_to_per_10k:\n",
    "            seg_risk *= 10_000.0\n",
    "\n",
    "        if u not in G:\n",
    "            G.add_node(u, x=u[0], y=u[1])\n",
    "        if v not in G:\n",
    "            G.add_node(v, x=v[0], y=v[1])\n",
    "\n",
    "        G.add_edge(\n",
    "            u,\n",
    "            v,\n",
    "            segment_id=seg_id,\n",
    "            length_m=length_m,\n",
    "            seg_risk=seg_risk,\n",
    "            geometry=geom,\n",
    "        )\n",
    "\n",
    "    if G.number_of_edges() == 0:\n",
    "        raise ValueError(f\"Graph has 0 edges for year={year}, month={month} after filtering. Check exposure coverage and filters.\")\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "# Cost and risk attributes\n",
    "@dataclass(frozen=True)\n",
    "class RiskConfig:\n",
    "    eta: float = 1.0  # weight of junction penalty inside the R(P) objective\n",
    "\n",
    "\n",
    "def add_node_penalty_attributes(\n",
    "    G: nx.Graph,\n",
    "    *,\n",
    "    node_risk_by_node_id: Optional[Dict[str, float]] = None,\n",
    ") -> None:\n",
    "    if node_risk_by_node_id is None:\n",
    "        node_risk_by_node_id = {}\n",
    "\n",
    "    for u, v, k, data in _iter_edges(G):\n",
    "        uid = G.nodes[u].get(\"node_id\")\n",
    "        vid = G.nodes[v].get(\"node_id\")\n",
    "        ru = float(node_risk_by_node_id.get(uid, 0.0)) if uid is not None else 0.0\n",
    "        rv = float(node_risk_by_node_id.get(vid, 0.0)) if vid is not None else 0.0\n",
    "        node_penalty = 0.5 * (ru + rv)\n",
    "\n",
    "        if isinstance(G, nx.MultiGraph):\n",
    "            G.edges[u, v, k][\"node_penalty\"] = float(node_penalty)\n",
    "        else:\n",
    "            data[\"node_penalty\"] = float(node_penalty)\n",
    "\n",
    "\n",
    "def add_risk_total_attributes(\n",
    "    G: nx.Graph,\n",
    "    *,\n",
    "    risk_cfg: RiskConfig = RiskConfig(eta=1.0),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Adds 'risk_total' to each edge:\n",
    "      risk_total = seg_risk + eta * node_penalty\n",
    "\n",
    "    Requires: seg_risk exists; node_penalty exists (0 if no node ids/risks attached).\n",
    "    \"\"\"\n",
    "    for u, v, k, data in _iter_edges(G):\n",
    "        seg_risk = float(data.get(\"seg_risk\", 0.0))\n",
    "        node_penalty = float(data.get(\"node_penalty\", 0.0))\n",
    "        risk_total = seg_risk + risk_cfg.eta * node_penalty\n",
    "\n",
    "        if isinstance(G, nx.MultiGraph):\n",
    "            G.edges[u, v, k][\"risk_total\"] = float(risk_total)\n",
    "        else:\n",
    "            data[\"risk_total\"] = float(risk_total)\n",
    "\n",
    "\n",
    "# Routing utilities\n",
    "\n",
    "def nearest_graph_node(\n",
    "    G: nx.Graph,\n",
    "    lon: float,\n",
    "    lat: float,\n",
    "    *,\n",
    "    metric_epsg: int = 32633,\n",
    ") -> NodeKey:\n",
    "    \"\"\"\n",
    "    Snap an (lon, lat) point to the closest graph node.\n",
    "    Brute force over nodes (OK for moderate graphs). Replace with KDTree if needed.\n",
    "    \"\"\"\n",
    "    p = gpd.GeoSeries([Point(lon, lat)], crs=\"EPSG:4326\").to_crs(epsg=metric_epsg).iloc[0]\n",
    "    x, y = float(p.x), float(p.y)\n",
    "\n",
    "    nodes = list(G.nodes())\n",
    "    if len(nodes) == 0:\n",
    "        raise ValueError(\"Graph has no nodes\")\n",
    "\n",
    "    xy = np.array(nodes, dtype=float)\n",
    "    d2 = (xy[:, 0] - x) ** 2 + (xy[:, 1] - y) ** 2\n",
    "    idx = int(d2.argmin())\n",
    "    return nodes[idx]\n",
    "\n",
    "\n",
    "def route_stats(G: nx.Graph, path: List[NodeKey], *, choose_by: str = \"length_m\") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Summarize route length and risk along a node-path.\n",
    "\n",
    "    For MultiGraph, the parallel edge between consecutive nodes is chosen by\n",
    "    minimizing choose_by. This MUST match the weight used when the path was computed,\n",
    "    otherwise stats can be inconsistent.\n",
    "    \"\"\"\n",
    "    total_len = 0.0\n",
    "    total_seg_risk = 0.0\n",
    "    total_node_penalty = 0.0\n",
    "    total_risk_total = 0.0\n",
    "\n",
    "    for a, b in zip(path[:-1], path[1:]):\n",
    "        d = _get_edge_data_for_step(G, a, b, choose_by=choose_by)\n",
    "\n",
    "        total_len += float(d.get(\"length_m\", 0.0))\n",
    "        total_seg_risk += float(d.get(\"seg_risk\", 0.0))\n",
    "        total_node_penalty += float(d.get(\"node_penalty\", 0.0))\n",
    "        total_risk_total += float(d.get(\"risk_total\", d.get(\"seg_risk\", 0.0)))\n",
    "\n",
    "    return {\n",
    "        \"length_m\": total_len,\n",
    "        \"seg_risk_sum\": total_seg_risk,\n",
    "        \"node_penalty_sum\": total_node_penalty,\n",
    "        \"risk_total_sum\": total_risk_total,\n",
    "    }\n",
    "\n",
    "\n",
    "def shortest_path_by(G: nx.Graph, source: NodeKey, target: NodeKey, weight: str) -> Optional[List[NodeKey]]:\n",
    "    try:\n",
    "        return nx.shortest_path(G, source=source, target=target, weight=weight, method=\"dijkstra\")\n",
    "    except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "        return None\n",
    "\n",
    "\n",
    "def constrained_min_risk_route(\n",
    "    G: nx.Graph,\n",
    "    source: NodeKey,\n",
    "    target: NodeKey,\n",
    "    *,\n",
    "    eps: float = 0.10,                 # allow up to +10% distance over shortest\n",
    "    length_attr: str = \"length_m\",\n",
    "    risk_attr: str = \"risk_total\",\n",
    "    lambdas: Optional[List[float]] = None,\n",
    ") -> Optional[List[NodeKey]]:\n",
    "    \"\"\"\n",
    "    Minimize risk subject to length <= (1+eps) * shortest_length.\n",
    "\n",
    "    Implementation: parametric sweep with a weighted sum:\n",
    "      minimize (risk + lambda * length)\n",
    "    and select the best path that satisfies the length constraint.\n",
    "    \"\"\"\n",
    "    shortest_len_path = shortest_path_by(G, source, target, weight=length_attr)\n",
    "    if shortest_len_path is None:\n",
    "        return None  # disconnected\n",
    "\n",
    "    shortest_len = route_stats(G, shortest_len_path, choose_by=length_attr)[\"length_m\"]\n",
    "    max_len = (1.0 + eps) * shortest_len\n",
    "\n",
    "    if lambdas is None:\n",
    "        lambdas = [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "    best_path: Optional[List[NodeKey]] = None\n",
    "    best_risk: Optional[float] = None\n",
    "    best_len: Optional[float] = None\n",
    "\n",
    "    for lam in lambdas:\n",
    "        # Build temporary combined weight on edges: risk + lambda*length\n",
    "        for u, v, k, d in _iter_edges(G):\n",
    "            comb = float(d.get(risk_attr, 0.0)) + lam * float(d.get(length_attr, 0.0))\n",
    "            if isinstance(G, nx.MultiGraph):\n",
    "                G.edges[u, v, k][\"_comb\"] = comb\n",
    "            else:\n",
    "                d[\"_comb\"] = comb\n",
    "\n",
    "        p = shortest_path_by(G, source, target, weight=\"_comb\")\n",
    "        if p is None:\n",
    "            continue\n",
    "\n",
    "        st = route_stats(G, p, choose_by=\"_comb\")  # consistent parallel-edge choice\n",
    "\n",
    "        if st[\"length_m\"] <= max_len:\n",
    "            candidate_risk = st[\"risk_total_sum\"]  \n",
    "            if (\n",
    "                best_path is None\n",
    "                or candidate_risk < best_risk\n",
    "                or (candidate_risk == best_risk and st[\"length_m\"] < best_len)\n",
    "            ):\n",
    "                best_path = p\n",
    "                best_risk = candidate_risk\n",
    "                best_len = st[\"length_m\"]\n",
    "\n",
    "    return best_path if best_path is not None else shortest_len_path\n",
    "\n",
    "\n",
    "# End-to-end wrapper\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RoutingMonthArtifacts:\n",
    "    G: nx.Graph\n",
    "    year: int\n",
    "    month: int\n",
    "    segment_risk_col_used: str\n",
    "    node_risk_col_used: Optional[str]\n",
    "    notes: str\n",
    "\n",
    "\n",
    "def build_graph_with_risk_for_month(\n",
    "    segments_panel_gdf: gpd.GeoDataFrame,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    *,\n",
    "    crossings_gdf: Optional[gpd.GeoDataFrame] = None,\n",
    "    junction_panel_gdf: Optional[gpd.GeoDataFrame] = None,\n",
    "    graph_cfg: GraphBuildConfig = GraphBuildConfig(),\n",
    "    node_risk_col: str = \"risk_accidents_per_10k_trips\",\n",
    "    node_snap_m: float = 30.0,\n",
    "    node_risk_fallback_strategy: str = \"median\",\n",
    "    node_risk_fallback_default: float = 0.0,\n",
    "    risk_cfg: RiskConfig = RiskConfig(eta=1.0),\n",
    ") -> RoutingMonthArtifacts:\n",
    "    \"\"\"\n",
    "    Build the month-specific routing graph and attach cost/risk attributes.\n",
    "\n",
    "      1) Build graph edges from segment panel for (year, month)\n",
    "      2) Optionally attach node_ids to graph nodes by snapping crossings_gdf points\n",
    "      3) Optionally build node risk lookup from junction_panel_gdf for (year, month)\n",
    "      4) Add edge costs and risk_total (segment + eta * junction penalty)\n",
    "    \"\"\"\n",
    "    G = build_routing_graph_for_month(segments_panel_gdf, year, month, config=graph_cfg)\n",
    "\n",
    "    node_risk_lookup: Dict[str, float] = {}\n",
    "    used_node_risk_col: Optional[str] = None\n",
    "    notes: List[str] = []\n",
    "\n",
    "    # junction info is needed\n",
    "    need_junction = (risk_cfg.eta != 0.0)\n",
    "\n",
    "    if need_junction:\n",
    "        if crossings_gdf is None or junction_panel_gdf is None:\n",
    "            notes.append(\"junction risk requested (eta!=0) but crossings_gdf/junction_panel_gdf not provided -> junction penalty set to 0.\")\n",
    "        else:\n",
    "            _attach_node_ids_to_graph_nodes(\n",
    "                G,\n",
    "                crossings_gdf,\n",
    "                metric_epsg=graph_cfg.metric_epsg,\n",
    "                node_id_col=\"node_id\",\n",
    "                max_snap_m=node_snap_m,\n",
    "            )\n",
    "            node_risk_lookup = _build_node_risk_lookup(\n",
    "                junction_panel_gdf,\n",
    "                year,\n",
    "                month,\n",
    "                node_id_col=\"node_id\",\n",
    "                node_risk_col=node_risk_col,\n",
    "                fallback=node_risk_fallback_default,\n",
    "                fallback_strategy=node_risk_fallback_strategy,\n",
    "            )\n",
    "            used_node_risk_col = node_risk_col\n",
    "\n",
    "            attached = sum(1 for n in G.nodes if \"node_id\" in G.nodes[n])\n",
    "            notes.append(f\"Attached node_id to {attached}/{G.number_of_nodes()} graph nodes (snap<= {node_snap_m}m).\")\n",
    "\n",
    "    add_node_penalty_attributes(G, node_risk_by_node_id=node_risk_lookup)\n",
    "    add_risk_total_attributes(G, risk_cfg=risk_cfg)\n",
    "\n",
    "    # Determine which segment risk column was used (for transparency)\n",
    "    seg_risk_col_used = None\n",
    "    for c in graph_cfg.seg_risk_col_candidates:\n",
    "        if c in segments_panel_gdf.columns:\n",
    "            seg_risk_col_used = c\n",
    "            break\n",
    "    if seg_risk_col_used is None:\n",
    "        seg_risk_col_used = \"(unknown)\"\n",
    "\n",
    "    # If per-trip risk was used but scaled, note it\n",
    "    if seg_risk_col_used == \"risk_accidents_per_trip\" and graph_cfg.auto_scale_trip_risk_to_per_10k:\n",
    "        notes.append(\"Scaled segment risk_accidents_per_trip by 10,000 for routing stability (per-10k trips).\")\n",
    "\n",
    "    if risk_cfg.eta != 0.0:\n",
    "        notes.append(f\"Risk objective uses eta={risk_cfg.eta} for junction penalty weighting.\")\n",
    "\n",
    "    return RoutingMonthArtifacts(\n",
    "        G=G,\n",
    "        year=year,\n",
    "        month=month,\n",
    "        segment_risk_col_used=seg_risk_col_used,\n",
    "        node_risk_col_used=used_node_risk_col,\n",
    "        notes=\" \".join(notes).strip(),\n",
    "    )\n",
    "\n",
    "\n",
    "# Verification utilities\n",
    "\n",
    "def verify_graph_sanity(\n",
    "    artifacts: RoutingMonthArtifacts,\n",
    "    *,\n",
    "    expect_junction_penalties: bool = False,\n",
    ") -> Dict[str, Union[int, float, str]]:\n",
    "    \"\"\"\n",
    "    Quick, paper-friendly sanity checks:\n",
    "      - graph non-empty\n",
    "      - risk magnitude reasonable\n",
    "      - node_penalty and risk_total ranges\n",
    "      - node ids attached when expected\n",
    "    \"\"\"\n",
    "    G = artifacts.G\n",
    "\n",
    "    seg_risks = [float(d.get(\"seg_risk\", 0.0)) for _, _, _, d in _iter_edges(G)]\n",
    "    risk_totals = [float(d.get(\"risk_total\", 0.0)) for _, _, _, d in _iter_edges(G)]\n",
    "    lengths = [float(d.get(\"length_m\", 0.0)) for _, _, _, d in _iter_edges(G)]\n",
    "    node_pen = [float(d.get(\"node_penalty\", 0.0)) for _, _, _, d in _iter_edges(G)]\n",
    "\n",
    "    attached_nodes = sum(1 for n in G.nodes if \"node_id\" in G.nodes[n])\n",
    "\n",
    "    out: Dict[str, Union[int, float, str]] = {\n",
    "        \"n_nodes\": G.number_of_nodes(),\n",
    "        \"n_edges\": G.number_of_edges(),\n",
    "        \"seg_risk_min\": float(np.min(seg_risks)) if seg_risks else float(\"nan\"),\n",
    "        \"seg_risk_median\": float(np.median(seg_risks)) if seg_risks else float(\"nan\"),\n",
    "        \"seg_risk_max\": float(np.max(seg_risks)) if seg_risks else float(\"nan\"),\n",
    "        \"risk_total_median\": float(np.median(risk_totals)) if risk_totals else float(\"nan\"),\n",
    "        \"risk_total_max\": float(np.max(risk_totals)) if risk_totals else float(\"nan\"),\n",
    "        \"length_median\": float(np.median(lengths)) if lengths else float(\"nan\"),\n",
    "        \"node_penalty_nonzero_share\": float(np.mean(np.array(node_pen) > 0)) if node_pen else 0.0,\n",
    "        \"graph_node_ids_attached\": attached_nodes,\n",
    "        \"notes\": artifacts.notes,\n",
    "    }\n",
    "\n",
    "    if expect_junction_penalties and attached_nodes == 0:\n",
    "        out[\"warning\"] = \"Expected junction penalties, but no graph nodes have node_id attached. Check snapping tolerance and CRS.\"\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde4ad0",
   "metadata": {},
   "source": [
    "## Run routing for one OD pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a543dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "{'n_nodes': 3074, 'n_edges': 4395, 'seg_risk_min': 0.0, 'seg_risk_median': 0.0, 'seg_risk_max': 4000.0, 'risk_total_median': 0.0, 'risk_total_max': 4000.0, 'length_median': 371.8095742150327, 'node_penalty_nonzero_share': 0.08964732650739476, 'graph_node_ids_attached': 2882, 'notes': 'Attached node_id to 2882/3074 graph nodes (snap<= 20.0m). Risk objective uses eta=1.0 for junction penalty weighting.'}\n",
      "Shortest length stats: {'length_m': 6599.195578921126, 'seg_risk_sum': 0.0, 'node_penalty_sum': 0.0, 'risk_total_sum': 0.0}\n",
      "Constrained min-risk stats: {'length_m': 6599.195578921126, 'seg_risk_sum': 0.0, 'node_penalty_sum': 0.0, 'risk_total_sum': 0.0}\n",
      "ΔL: 0.0 ΔR: None\n"
     ]
    }
   ],
   "source": [
    "# Run routing for ONE OD pair\n",
    "\n",
    "def run_one_od_routing(\n",
    "    *,\n",
    "    segments_panel_gdf: gpd.GeoDataFrame,\n",
    "    crossings_gdf: gpd.GeoDataFrame,\n",
    "    junction_panel_gdf: gpd.GeoDataFrame,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    origin_lonlat: tuple[float, float],\n",
    "    dest_lonlat: tuple[float, float],\n",
    "    eps: float = 0.10,\n",
    "    eta: float = 1.0,\n",
    "    metric_epsg: int = 32633,\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds the month graph, snaps OD to graph nodes, and returns:\n",
    "      - shortest-by-length route (P_dist)\n",
    "      - constrained min-risk route within (1+eps) distance (P_safe), minimizing risk_total\n",
    "      - optional shortest-by-cost route (mixed objective) for comparison\n",
    "\n",
    "    origin_lonlat/dest_lonlat are (lon, lat) in EPSG:4326.\n",
    "    \"\"\"\n",
    "    artifacts = build_graph_with_risk_for_month(\n",
    "        segments_panel_gdf,\n",
    "        year,\n",
    "        month,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_panel_gdf=junction_panel_gdf,\n",
    "        graph_cfg=GraphBuildConfig(metric_epsg=metric_epsg),\n",
    "        risk_cfg=RiskConfig(eta=eta),\n",
    "        node_snap_m=20.0,\n",
    "    )\n",
    "\n",
    "    sanity = verify_graph_sanity(\n",
    "        artifacts,\n",
    "        expect_junction_penalties=(eta != 0.0),\n",
    "    )\n",
    "\n",
    "    G = artifacts.G\n",
    "    o_lon, o_lat = origin_lonlat\n",
    "    d_lon, d_lat = dest_lonlat\n",
    "\n",
    "    src = nearest_graph_node(G, o_lon, o_lat, metric_epsg=metric_epsg)\n",
    "    dst = nearest_graph_node(G, d_lon, d_lat, metric_epsg=metric_epsg)\n",
    "\n",
    "    # Baseline: shortest distance (P_dist)\n",
    "    p_len = shortest_path_by(G, src, dst, weight=\"length_m\")\n",
    "    if p_len is None:\n",
    "        return {\n",
    "            \"status\": \"disconnected\",\n",
    "            \"graph_sanity\": sanity,\n",
    "            \"origin_node\": src,\n",
    "            \"dest_node\": dst,\n",
    "            \"notes\": artifacts.notes,\n",
    "        }\n",
    "    st_len = route_stats(G, p_len, choose_by=\"length_m\")\n",
    "\n",
    "    # Constrained min-risk (P_safe) minimizing risk_total, with detour constraint\n",
    "    p_safe = constrained_min_risk_route(\n",
    "        G,\n",
    "        src,\n",
    "        dst,\n",
    "        eps=eps,\n",
    "        length_attr=\"length_m\",\n",
    "        risk_attr=\"risk_total\",\n",
    "    )\n",
    "    # If graph is connected, p_safe will at least fall back to p_len (see routing util)\n",
    "    st_safe = route_stats(G, p_safe, choose_by=\"risk_total\") if p_safe is not None else None\n",
    "\n",
    "    \n",
    "    # Compute deltas \n",
    "    delta_L = (st_safe[\"length_m\"] - st_len[\"length_m\"]) / st_len[\"length_m\"] if st_safe else None\n",
    "    if st_len[\"risk_total_sum\"] > 0 and st_safe is not None:\n",
    "        delta_R = (st_len[\"risk_total_sum\"] - st_safe[\"risk_total_sum\"]) / st_len[\"risk_total_sum\"]\n",
    "    else:\n",
    "        delta_R = None\n",
    "\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"graph_sanity\": sanity,\n",
    "        \"origin_node\": src,\n",
    "        \"dest_node\": dst,\n",
    "        \"shortest_length_path\": p_len,\n",
    "        \"shortest_length_stats\": st_len,\n",
    "        \"constrained_min_risk_path\": p_safe,\n",
    "        \"constrained_min_risk_stats\": st_safe,\n",
    "        \"delta_L\": delta_L,\n",
    "        \"delta_R\": delta_R,\n",
    "        \"notes\": artifacts.notes,\n",
    "        \"params\": {\n",
    "            \"eps\": eps,\n",
    "            \"eta\": eta,\n",
    "        },\n",
    "        \"graph\": G,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "result = run_one_od_routing(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    year=2021, month=6,\n",
    "    origin_lonlat=(13.3777, 52.5163),\n",
    "    dest_lonlat=(13.4541, 52.5110),\n",
    "    eps=0.10,\n",
    "    eta=1.0,                          \n",
    ")\n",
    "\n",
    "print(result[\"status\"])\n",
    "print(result[\"graph_sanity\"])\n",
    "if result[\"status\"] == \"ok\":\n",
    "    print(\"Shortest length stats:\", result[\"shortest_length_stats\"])\n",
    "    print(\"Constrained min-risk stats:\", result[\"constrained_min_risk_stats\"])\n",
    "    print(\"ΔL:\", result[\"delta_L\"], \"ΔR:\", result[\"delta_R\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5effb40",
   "metadata": {},
   "source": [
    "## Evaluation loop over many OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "807a5030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_nodes': 3074, 'n_edges': 4395, 'seg_risk_min': 0.0, 'seg_risk_median': 0.0, 'seg_risk_max': 4000.0, 'risk_total_median': 0.0, 'risk_total_max': 4000.0, 'length_median': 371.8095742150327, 'node_penalty_nonzero_share': 0.08964732650739476, 'graph_node_ids_attached': 2882, 'notes': 'Attached node_id to 2882/3074 graph nodes (snap<= 20.0m). Risk objective uses eta=1.0 for junction penalty weighting.'}\n",
      "          delta_L     delta_R\n",
      "count  300.000000  281.000000\n",
      "mean     0.041628    0.738203\n",
      "std      0.031892    0.340096\n",
      "min      0.000000    0.000000\n",
      "25%      0.010479    0.609771\n",
      "50%      0.040833    0.902206\n",
      "75%      0.068713    1.000000\n",
      "max      0.099990    1.000000\n"
     ]
    }
   ],
   "source": [
    "# Extensive evaluation loop over MANY OD pairs\n",
    "\n",
    "def _sample_reachable_od_pairs(\n",
    "    G: nx.Graph,\n",
    "    n_pairs: int,\n",
    "    *,\n",
    "    seed: int = 7,\n",
    "    min_euclid_m: float = 1500.0,\n",
    "    max_tries: int = 200000,\n",
    ") -> list[tuple[NodeKey, NodeKey]]:\n",
    "    \"\"\"\n",
    "    Samples OD pairs as graph nodes ensuring:\n",
    "      - O != D\n",
    "      - straight-line distance >= min_euclid_m\n",
    "      - O and D are connected (same component) in the undirected sense\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    nodes = list(G.nodes())\n",
    "    if len(nodes) < 2:\n",
    "        return []\n",
    "\n",
    "    comp_map = {}\n",
    "    for cid, comp in enumerate(nx.connected_components(G.to_undirected())):\n",
    "        for n in comp:\n",
    "            comp_map[n] = cid\n",
    "\n",
    "    pairs: list[tuple[NodeKey, NodeKey]] = []\n",
    "    tries = 0\n",
    "    while len(pairs) < n_pairs and tries < max_tries:\n",
    "        tries += 1\n",
    "        a = rng.choice(nodes)\n",
    "        b = rng.choice(nodes)\n",
    "        if a == b:\n",
    "            continue\n",
    "        if comp_map.get(a) != comp_map.get(b):\n",
    "            continue\n",
    "\n",
    "        dx = float(a[0] - b[0])\n",
    "        dy = float(a[1] - b[1])\n",
    "        if math.sqrt(dx * dx + dy * dy) < min_euclid_m:\n",
    "            continue\n",
    "\n",
    "        pairs.append((a, b))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def evaluate_many_od_pairs(\n",
    "    *,\n",
    "    segments_panel_gdf: gpd.GeoDataFrame,\n",
    "    crossings_gdf: gpd.GeoDataFrame,\n",
    "    junction_panel_gdf: gpd.GeoDataFrame,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    n_pairs: int = 200,\n",
    "    eps: float = 0.10,\n",
    "    eta: float = 1.0, # junction importance\n",
    "    metric_epsg: int = 32633,\n",
    "    seed: int = 7,\n",
    "    min_euclid_m: float = 1500.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Builds month graph once, samples many reachable OD pairs on the graph,\n",
    "    and evaluates:\n",
    "      - shortest-by-length (P_dist)\n",
    "      - optional shortest-by-cost (mixed objective)\n",
    "      - constrained min-risk (P_safe) minimizing risk_total under length constraint\n",
    "\n",
    "    Returns a DataFrame with per-OD statistics + metadata.\n",
    "    \"\"\"\n",
    "    artifacts = build_graph_with_risk_for_month(\n",
    "        segments_panel_gdf,\n",
    "        year,\n",
    "        month,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_panel_gdf=junction_panel_gdf,\n",
    "        graph_cfg=GraphBuildConfig(metric_epsg=metric_epsg),\n",
    "        risk_cfg=RiskConfig(eta=eta),\n",
    "        node_snap_m=20.0,\n",
    "    )\n",
    "\n",
    "    sanity = verify_graph_sanity(\n",
    "        artifacts,\n",
    "        expect_junction_penalties=(eta != 0.0),\n",
    "    )\n",
    "    G = artifacts.G\n",
    "\n",
    "    od_pairs = _sample_reachable_od_pairs(G, n_pairs, seed=seed, min_euclid_m=min_euclid_m)\n",
    "    if len(od_pairs) == 0:\n",
    "        raise ValueError(\"Could not sample any reachable OD pairs. Check graph connectivity / size.\")\n",
    "\n",
    "    rows = []\n",
    "    n_skipped = 0\n",
    "\n",
    "    for i, (src, dst) in enumerate(od_pairs):\n",
    "        # 1) Shortest length (P_dist)\n",
    "        p_len = shortest_path_by(G, src, dst, weight=\"length_m\")\n",
    "        if p_len is None:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        st_len = route_stats(G, p_len, choose_by=\"length_m\")\n",
    "        shortest_len = float(st_len[\"length_m\"])\n",
    "        max_len = (1.0 + eps) * shortest_len\n",
    "\n",
    "        \n",
    "        # 2) Constrained min-risk minimizing risk_total\n",
    "        p_safe = constrained_min_risk_route(\n",
    "            G,\n",
    "            src,\n",
    "            dst,\n",
    "            eps=eps,\n",
    "            length_attr=\"length_m\",\n",
    "            risk_attr=\"risk_total\",\n",
    "        )\n",
    "        if p_safe is None:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        st_safe = route_stats(G, p_safe, choose_by=\"risk_total\")\n",
    "\n",
    "        # Route-level risk in Methods is R(P) = sum risk_total\n",
    "        R_len = float(st_len[\"risk_total_sum\"])\n",
    "        R_safe = float(st_safe[\"risk_total_sum\"])\n",
    "\n",
    "        row = {\n",
    "            \"pair_idx\": i,\n",
    "            \"src_x\": float(src[0]),\n",
    "            \"src_y\": float(src[1]),\n",
    "            \"dst_x\": float(dst[0]),\n",
    "            \"dst_y\": float(dst[1]),\n",
    "\n",
    "            \"shortest_len_m\": shortest_len,\n",
    "            \"shortest_risk_total_sum\": R_len,\n",
    "\n",
    "            \"safe_len_m\": float(st_safe[\"length_m\"]),\n",
    "            \"safe_risk_total_sum\": R_safe,\n",
    "\n",
    "            \"len_constraint_max_m\": float(max_len),\n",
    "            \"safe_feasible\": bool(float(st_safe[\"length_m\"]) <= max_len + 1e-6),\n",
    "        }\n",
    "\n",
    "        \n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Trade-offs relative to shortest-distance route\n",
    "    df[\"delta_L\"] = (df[\"safe_len_m\"] - df[\"shortest_len_m\"]) / df[\"shortest_len_m\"]\n",
    "    df[\"delta_R\"] = (df[\"shortest_risk_total_sum\"] - df[\"safe_risk_total_sum\"]) / df[\"shortest_risk_total_sum\"].replace(0, np.nan)\n",
    "\n",
    "    \n",
    "    # Metadata for reproducibility\n",
    "    df.attrs[\"graph_sanity\"] = sanity\n",
    "    df.attrs[\"notes\"] = artifacts.notes\n",
    "    df.attrs[\"year\"] = year\n",
    "    df.attrs[\"month\"] = month\n",
    "    df.attrs[\"eps\"] = eps\n",
    "    df.attrs[\"eta\"] = eta\n",
    "    df.attrs[\"seed\"] = seed\n",
    "    df.attrs[\"min_euclid_m\"] = min_euclid_m\n",
    "    df.attrs[\"n_pairs_requested\"] = n_pairs\n",
    "    df.attrs[\"n_pairs_sampled\"] = len(od_pairs)\n",
    "    df.attrs[\"n_pairs_used\"] = len(df)\n",
    "    df.attrs[\"n_pairs_skipped\"] = n_skipped\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "eval_df = evaluate_many_od_pairs(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    year=2021, month=6,\n",
    "    n_pairs=300,\n",
    "    eps=0.10,\n",
    "    eta=1.0,             \n",
    "    seed=7,\n",
    "    min_euclid_m=2000.0,\n",
    ")\n",
    "print(eval_df.attrs[\"graph_sanity\"])\n",
    "print(eval_df[[\"delta_L\", \"delta_R\"]].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d345f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08964732650739476"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.attrs[\"graph_sanity\"][\"node_penalty_nonzero_share\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ced1d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['safe_feasible'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff1429",
   "metadata": {},
   "source": [
    "## Loop routing over all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e849d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "ETA = 1.0        \n",
    "EPS = 0.10       \n",
    "N_PAIRS = 200\n",
    "\n",
    "for (year, month), _ in segments_df.groupby([\"year\", \"month\"]):\n",
    "    try:\n",
    "        eval_df = evaluate_many_od_pairs(\n",
    "            segments_panel_gdf=segments_df,\n",
    "            crossings_gdf=crossings_gdf,\n",
    "            junction_panel_gdf=junction_df,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            n_pairs=N_PAIRS,\n",
    "            eps=EPS,\n",
    "            eta=ETA,                \n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # e.g. no reachable OD pairs in this month\n",
    "        print(f\"[skip] {year}-{month}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if len(eval_df) == 0:\n",
    "        print(f\"[skip] {year}-{month}: empty evaluation frame\")\n",
    "        continue\n",
    "\n",
    "    eval_df[\"year\"] = year\n",
    "    eval_df[\"month\"] = month\n",
    "    eval_df[\"eta\"] = ETA\n",
    "    eval_df[\"eps\"] = EPS\n",
    "\n",
    "    results.append(eval_df)\n",
    "\n",
    "if len(results) == 0:\n",
    "    raise RuntimeError(\"No valid OD-pair evaluations across any month.\")\n",
    "\n",
    "all_months_eval = pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65e833b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_L</th>\n",
       "      <th>delta_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12000.000000</td>\n",
       "      <td>10489.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.767296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.355378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.643497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.028799</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.061455</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.131090</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            delta_L       delta_R\n",
       "count  12000.000000  10489.000000\n",
       "mean       0.035037      0.767296\n",
       "std        0.031725      0.355378\n",
       "min        0.000000      0.000000\n",
       "25%        0.001514      0.643497\n",
       "50%        0.028799      1.000000\n",
       "75%        0.061455      1.000000\n",
       "max        0.131090      1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_months_eval[[\"delta_L\", \"delta_R\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77f61de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_months_eval.attrs if hasattr(all_months_eval, \"attrs\") else \"attrs lost on concat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157b08a",
   "metadata": {},
   "source": [
    "## Visual abtract safety-aware routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "142cea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month = 2021, 6\n",
    "\n",
    "# Example (use your actual values or sampled ones)\n",
    "origin_lonlat = (13.4037, 52.5365)  # (lon, lat)\n",
    "dest_lonlat   = (13.4047, 52.4989)  # (lon, lat)\n",
    "\n",
    "# Make key method params explicit for reproducibility\n",
    "EPS = 0.10\n",
    "ETA = 1.0\n",
    "\n",
    "result_berlin = run_one_od_routing(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    year=year,\n",
    "    month=month,\n",
    "    origin_lonlat=origin_lonlat,\n",
    "    dest_lonlat=dest_lonlat,\n",
    "    eps=EPS,\n",
    "    eta=ETA,          \n",
    ")\n",
    "\n",
    "if result_berlin.get(\"status\") == \"disconnected\":\n",
    "    raise RuntimeError(f\"OD pair disconnected for {year}-{month} after exposure filtering.\")\n",
    "\n",
    "# Always use these:\n",
    "ox, oy = origin_lonlat\n",
    "dx, dy = dest_lonlat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee300de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "\n",
    "metric_epsg = 32633  # UTM\n",
    "\n",
    "# Use the same graph that produced the paths\n",
    "G = result_berlin.get(\"graph\", None)\n",
    "if G is None:\n",
    "    # Fallback\n",
    "    artifacts = build_graph_with_risk_for_month(\n",
    "        segments_panel_gdf=segments_df,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_panel_gdf=junction_df,\n",
    "        year=year,\n",
    "        month=month,\n",
    "        risk_cfg=RiskConfig(eta=1.0),\n",
    "    )\n",
    "    G = artifacts.G\n",
    "\n",
    "\n",
    "def _flatten_lines(geom):\n",
    "    \"\"\"Return a list of LineStrings from LineString/MultiLineString.\"\"\"\n",
    "    if geom is None or geom.is_empty:\n",
    "        return []\n",
    "    if isinstance(geom, LineString):\n",
    "        return [geom]\n",
    "    # MultiLineString or GeometryCollection-like\n",
    "    try:\n",
    "        parts = list(geom.geoms)\n",
    "        out = []\n",
    "        for p in parts:\n",
    "            if isinstance(p, LineString) and not p.is_empty:\n",
    "                out.append(p)\n",
    "        return out\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def path_to_multiline_latlon(G, path_nodes, *, metric_epsg=32633, choose_by=\"length_m\"):\n",
    "    \"\"\"\n",
    "    Convert a node-path to a MultiLineString in lon/lat (EPSG:4326).\n",
    "    For MultiGraph, choose the parallel edge minimizing `choose_by`\n",
    "    so the plotted geometry is consistent with the intended objective.\n",
    "    \"\"\"\n",
    "    if path_nodes is None or len(path_nodes) < 2:\n",
    "        return None\n",
    "\n",
    "    geoms = []\n",
    "    for u, v in zip(path_nodes[:-1], path_nodes[1:]):\n",
    "        edge = None\n",
    "\n",
    "        if isinstance(G, nx.MultiGraph):\n",
    "            edges = G.get_edge_data(u, v) or {}\n",
    "            if not edges:\n",
    "                continue\n",
    "            best_key = min(\n",
    "                edges,\n",
    "                key=lambda k: float(edges[k].get(choose_by, edges[k].get(\"length_m\", float(\"inf\"))))\n",
    "            )\n",
    "            edge = edges[best_key]\n",
    "        else:\n",
    "            edge = G.get_edge_data(u, v) or {}\n",
    "\n",
    "        geom = edge.get(\"geometry\")\n",
    "        geoms.extend(_flatten_lines(geom))\n",
    "\n",
    "    if not geoms:\n",
    "        return None\n",
    "\n",
    "    ml = MultiLineString(geoms)\n",
    "    return gpd.GeoSeries([ml], crs=f\"EPSG:{metric_epsg}\").to_crs(epsg=4326).iloc[0]\n",
    "\n",
    "\n",
    "# Choose-by weights for consistent MultiGraph visualization\n",
    "shortest_geom = path_to_multiline_latlon(\n",
    "    G,\n",
    "    result_berlin[\"shortest_length_path\"],\n",
    "    metric_epsg=metric_epsg,\n",
    "    choose_by=\"length_m\",\n",
    ")\n",
    "\n",
    "safe_geom = path_to_multiline_latlon(\n",
    "    G,\n",
    "    result_berlin[\"constrained_min_risk_path\"],\n",
    "    metric_epsg=metric_epsg,\n",
    "    choose_by=\"risk_total\",\n",
    ")\n",
    "\n",
    "# OD points (lon, lat)\n",
    "ox, oy = origin_lonlat\n",
    "dx, dy = dest_lonlat\n",
    "\n",
    "# guard against lat/lon swap\n",
    "assert -180 <= ox <= 180 and -90 <= oy <= 90, \"origin must be (lon, lat)\"\n",
    "assert -180 <= dx <= 180 and -90 <= dy <= 90, \"dest must be (lon, lat)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cbd1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df = gpd.read_parquet(\n",
    "    \"../data/merged/berlin_bike_accident_strava_risk_core_panel.parquet\"\n",
    ").to_crs(epsg=4326)\n",
    "\n",
    "junction_df = gpd.read_parquet(\n",
    "    \"../data/merged/berlin_bike_accident_node_panel.parquet\"\n",
    ").to_crs(epsg=4326)\n",
    "\n",
    "segments_m  = segments_df.query(\"year == @year and month == @month\").copy()\n",
    "junctions_m = junction_df.query(\"year == @year and month == @month\").copy()\n",
    "\n",
    "# Optional convenience for any metric operations (buffers/extents/length checks)\n",
    "metric_epsg = 32633\n",
    "segments_m_utm  = segments_m.to_crs(epsg=metric_epsg)\n",
    "junctions_m_utm = junctions_m.to_crs(epsg=metric_epsg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6f4d0",
   "metadata": {},
   "source": [
    "## OD route for paper + length and constraint verficitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f6fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "from tueplots.constants.color import rgb\n",
    "\n",
    "# Fixed map snippet\n",
    "center_lat = 52.518589\n",
    "center_lon = 13.376665\n",
    "lat_tol = 2.4e-2\n",
    "lon_tol = 4.8e-2\n",
    "\n",
    "x0, x1 = center_lon - lon_tol, center_lon + lon_tol\n",
    "y0, y1 = center_lat - lat_tol, center_lat + lat_tol\n",
    "\n",
    "# Month used everywhere\n",
    "year, month = 2021, 6\n",
    "metric_epsg = 32633\n",
    "\n",
    "# Method parameters\n",
    "EPS = 0.10\n",
    "ETA = 1.0\n",
    "\n",
    "# Base layers for the same month\n",
    "segments_m  = segments_df.query(\"year == @year and month == @month\").copy()\n",
    "junctions_m = junction_df.query(\"year == @year and month == @month\").copy()\n",
    "\n",
    "# Pick random OD pair INSIDE that window set rng for reproducibility\n",
    "rng = np.random.default_rng(69)\n",
    "\n",
    "candidates = junctions_m.cx[x0:x1, y0:y1].copy()\n",
    "if \"degree\" in candidates.columns:\n",
    "    candidates = candidates.query(\"degree >= 3\")\n",
    "\n",
    "if len(candidates) < 2:\n",
    "    raise ValueError(\"Not enough junction candidates inside the fixed window. Increase lat_tol/lon_tol or relax filters.\")\n",
    "\n",
    "coords = np.column_stack([candidates.geometry.x.to_numpy(), candidates.geometry.y.to_numpy()])  # (lon, lat)\n",
    "i, j = rng.choice(len(coords), size=2, replace=False)\n",
    "\n",
    "origin_lonlat = (float(coords[i, 0]), float(coords[i, 1]))\n",
    "dest_lonlat   = (float(coords[j, 0]), float(coords[j, 1]))\n",
    "\n",
    "ox, oy = origin_lonlat\n",
    "dx, dy = dest_lonlat\n",
    "\n",
    "# Run routing to build the graph internally\n",
    "result_berlin = run_one_od_routing(\n",
    "    segments_panel_gdf=segments_df,\n",
    "    crossings_gdf=crossings_gdf,\n",
    "    junction_panel_gdf=junction_df,\n",
    "    year=year,\n",
    "    month=month,\n",
    "    origin_lonlat=origin_lonlat,\n",
    "    dest_lonlat=dest_lonlat,\n",
    "    eps=EPS,\n",
    "    eta=ETA,\n",
    ")\n",
    "\n",
    "if result_berlin.get(\"status\") == \"disconnected\":\n",
    "    raise RuntimeError(f\"OD pair disconnected for {year}-{month} after exposure filtering.\")\n",
    "\n",
    "G = result_berlin.get(\"graph\", None)\n",
    "if G is None:\n",
    "    # fallback \n",
    "    artifacts = build_graph_with_risk_for_month(\n",
    "        segments_panel_gdf=segments_df,\n",
    "        crossings_gdf=crossings_gdf,\n",
    "        junction_panel_gdf=junction_df,\n",
    "        year=year,\n",
    "        month=month,\n",
    "        risk_cfg=RiskConfig(eta=ETA),\n",
    "    )\n",
    "    G = artifacts.G\n",
    "\n",
    "\n",
    "def _flatten_lines(geom):\n",
    "    if geom is None or geom.is_empty:\n",
    "        return []\n",
    "    if isinstance(geom, LineString):\n",
    "        return [geom]\n",
    "    try:\n",
    "        return [g for g in geom.geoms if isinstance(g, LineString) and not g.is_empty]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def path_to_multiline_latlon(G, path_nodes, *, metric_epsg=32633, choose_by=\"length_m\"):\n",
    "    \"\"\"\n",
    "    Convert node path -> MultiLineString in EPSG:4326.\n",
    "    For MultiGraph, choose the parallel edge that minimizes choose_by so\n",
    "    plotted geometry matches the intended weight.\n",
    "    \"\"\"\n",
    "    if path_nodes is None or len(path_nodes) < 2:\n",
    "        return None\n",
    "\n",
    "    geoms = []\n",
    "    for u, v in zip(path_nodes[:-1], path_nodes[1:]):\n",
    "        if isinstance(G, nx.MultiGraph):\n",
    "            edges = G.get_edge_data(u, v) or {}\n",
    "            if not edges:\n",
    "                continue\n",
    "            best_key = min(\n",
    "                edges,\n",
    "                key=lambda k: float(edges[k].get(choose_by, edges[k].get(\"length_m\", float(\"inf\"))))\n",
    "            )\n",
    "            edge = edges[best_key]\n",
    "        else:\n",
    "            edge = G.get_edge_data(u, v) or {}\n",
    "\n",
    "        geoms.extend(_flatten_lines(edge.get(\"geometry\")))\n",
    "\n",
    "    if not geoms:\n",
    "        return None\n",
    "\n",
    "    ml = MultiLineString(geoms)\n",
    "    return gpd.GeoSeries([ml], crs=f\"EPSG:{metric_epsg}\").to_crs(epsg=4326).iloc[0]\n",
    "\n",
    "\n",
    "# Shortest path geometry: choose_by length\n",
    "shortest_geom = path_to_multiline_latlon(\n",
    "    G, result_berlin[\"shortest_length_path\"], metric_epsg=metric_epsg, choose_by=\"length_m\"\n",
    ")\n",
    "\n",
    "# Safe path geometry: choose_by risk_total\n",
    "safe_geom = path_to_multiline_latlon(\n",
    "    G, result_berlin[\"constrained_min_risk_path\"], metric_epsg=metric_epsg, choose_by=\"risk_total\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4f28057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths identical: False\n",
      "Shortest path length: 6834.3 m\n",
      "Safe route length:    7350.8 m\n",
      "Shortest route risk_total: 37.951\n",
      "Safe route risk_total:     16.347\n",
      "Detour: 7.56%\n",
      "Max allowed length: 7517.7 m\n",
      "Constraint satisfied.\n",
      "delta_L: 7.56%\n",
      "delta_R: 56.93%\n"
     ]
    }
   ],
   "source": [
    "# Check route lengths + detour constraint\n",
    "\n",
    "p_len = result_berlin[\"shortest_length_path\"]\n",
    "p_safe = result_berlin[\"constrained_min_risk_path\"]\n",
    "\n",
    "paths_identical = (p_len == p_safe)\n",
    "print(\"Paths identical:\", paths_identical)\n",
    "\n",
    "# Choose-by for MultiGraph edge selection:\n",
    "st_len  = route_stats(G, p_len,  choose_by=\"length_m\")\n",
    "st_safe = route_stats(G, p_safe, choose_by=\"risk_total\")\n",
    "\n",
    "shortest_length = float(st_len[\"length_m\"])\n",
    "safe_length     = float(st_safe[\"length_m\"])\n",
    "\n",
    "print(f\"Shortest path length: {shortest_length:.1f} m\")\n",
    "print(f\"Safe route length:    {safe_length:.1f} m\")\n",
    "\n",
    "# Report route risk \n",
    "print(f\"Shortest route risk_total: {float(st_len['risk_total_sum']):.3f}\")\n",
    "print(f\"Safe route risk_total:     {float(st_safe['risk_total_sum']):.3f}\")\n",
    "\n",
    "# Check detour constraint\n",
    "eps = result_berlin.get(\"params\", {}).get(\"eps\", result_berlin.get(\"eps\", 0.10))\n",
    "max_allowed = (1.0 + float(eps)) * shortest_length\n",
    "detour_pct = ((safe_length / shortest_length) - 1.0) * 100.0 if shortest_length > 0 else float(\"nan\")\n",
    "\n",
    "print(f\"Detour: {detour_pct:.2f}%\")\n",
    "print(f\"Max allowed length: {max_allowed:.1f} m\")\n",
    "\n",
    "if safe_length <= max_allowed + 1e-6:\n",
    "    print(\"Constraint satisfied.\")\n",
    "else:\n",
    "    print(\"WARNING: Constraint violated (check routing selection / edge-choice consistency).\")\n",
    "\n",
    "# Report deltas from result_berlin for cross-check\n",
    "if \"delta_L\" in result_berlin and result_berlin[\"delta_L\"] is not None:\n",
    "    print(f\"delta_L: {100*result_berlin['delta_L']:.2f}%\")\n",
    "if \"delta_R\" in result_berlin and result_berlin[\"delta_R\"] is not None:\n",
    "    print(f\"delta_R: {100*result_berlin['delta_R']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e72dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
